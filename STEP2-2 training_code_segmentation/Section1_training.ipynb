{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "!python -c \"import monai; import nibabel; import tqdm\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21번과 비교실험 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import shutil\n",
    "import tempfile\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    Resized,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandSpatialCropSamplesd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    EnsureTyped,\n",
    "    RandGaussianNoised,\n",
    "    RandGaussianSmoothd,\n",
    "    RandZoomd,\n",
    "    RandFlip,\n",
    "    RandRotate90,\n",
    "    RandAdjustContrast,\n",
    "    RandShiftIntensity,\n",
    "    RandSimulateLowResolutiond\n",
    "\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import (SwinUNETR, UNETR, UNet, DynUNet, SegResNet)\n",
    "\n",
    "from monai.data import (\n",
    "    ThreadDataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    "    set_track_meta,\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "def get_kernels_strides(patch_size, spacing):\n",
    "    \"\"\"\n",
    "    This function is only used for decathlon datasets with the provided patch sizes.\n",
    "    When refering this method for other tasks, please ensure that the patch size for each spatial dimension should\n",
    "    be divisible by the product of all strides in the corresponding dimension.\n",
    "    In addition, the minimal spatial size should have at least one dimension that has twice the size of\n",
    "    the product of all strides. For patch sizes that cannot find suitable strides, an error will be raised.\n",
    "\n",
    "    \"\"\"\n",
    "    sizes, spacings = patch_size, spacing\n",
    "    input_size = sizes\n",
    "    strides, kernels = [], []\n",
    "    while True:\n",
    "        spacing_ratio = [sp / min(spacings) for sp in spacings]\n",
    "        stride = [2 if ratio <= 2 and size >= 8 else 1 for (ratio, size) in zip(spacing_ratio, sizes)]\n",
    "        kernel = [3 if ratio <= 2 else 1 for ratio in spacing_ratio]\n",
    "        if all(s == 1 for s in stride):\n",
    "            break\n",
    "        for idx, (i, j) in enumerate(zip(sizes, stride)):\n",
    "            if i % j != 0:\n",
    "                raise ValueError(\n",
    "                    f\"Patch size is not supported, please try to modify the size {input_size[idx]} in the spatial dimension {idx}.\"\n",
    "                )\n",
    "        sizes = [i / j for i, j in zip(sizes, stride)]\n",
    "        spacings = [i * j for i, j in zip(spacings, stride)]\n",
    "        kernels.append(kernel)\n",
    "        strides.append(stride)\n",
    "\n",
    "    strides.insert(0, len(spacings) * [1])\n",
    "    kernels.append(len(spacings) * [3])\n",
    "    return kernels, strides\n",
    "class PolyLRScheduler(_LRScheduler):\n",
    "    def __init__(self, optimizer, initial_lr: float, max_steps: int, exponent: float = 0.9, current_step: int = None):\n",
    "        self.optimizer = optimizer\n",
    "        self.initial_lr = initial_lr\n",
    "        self.max_steps = max_steps\n",
    "        self.exponent = exponent\n",
    "        self.ctr = 0\n",
    "        super().__init__(optimizer, current_step if current_step is not None else -1, False)\n",
    "\n",
    "    def step(self, current_step=None):\n",
    "        if current_step is None or current_step == -1:\n",
    "            current_step = self.ctr\n",
    "            self.ctr += 1\n",
    "\n",
    "        new_lr = self.initial_lr * (1 - current_step / self.max_steps) ** self.exponent\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def oar_run_train(json_name):\n",
    "    \n",
    "    root_dir = r\"D:\\! project\\2024- AortaSeg\\data\\new_final\\zone1\"\n",
    "    data_root_dir = r\"D:\\! project\\2024- AortaSeg\\data\\new_final\\zone1\"\n",
    "    data_dir = root_dir + r\"/\"\n",
    "    num_samples = 2\n",
    "    model_savepath = os.path.join(data_root_dir, \"20240923model_%s\" %json_name)\n",
    "    loss_savepath = os.path.join(data_root_dir, \"20240923loss_%s\" %json_name)\n",
    "    os.makedirs(model_savepath)\n",
    "    os.makedirs(loss_savepath)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    space_x, space_y, space_z = 1.1, 1.1, 2.0\n",
    "    a_min, a_max, b_min, b_max = -175, 350, 0, 1\n",
    "    spatial_size_xyz = (128, 128, 112)\n",
    "    \n",
    "    train_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"], ensure_channel_first=True),\n",
    "                # Orientationd(keys=[\"image\", \"label\"], axcodes=\"LPS\"),\n",
    "                EnsureTyped(keys=[\"image\", \"label\"], device=device, track_meta=False),\n",
    "                RandRotate90d(\n",
    "                     keys=[\"image\", \"label\"],\n",
    "                     prob=0.3,\n",
    "                     max_k=3,\n",
    "                ),\n",
    "                RandZoomd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    min_zoom=0.7,\n",
    "                    max_zoom=1.4,\n",
    "                    mode=(\"trilinear\", \"nearest\"),\n",
    "                    align_corners=(True, None),\n",
    "                    prob=0.20,\n",
    "                ),\n",
    "                RandFlipd([\"image\", \"label\"], spatial_axis=[0], prob=0.5),\n",
    "                RandFlipd([\"image\", \"label\"], spatial_axis=[1], prob=0.5),\n",
    "                RandFlipd([\"image\", \"label\"], spatial_axis=[2], prob=0.5),\n",
    "                # RandCropByPosNegLabeld(\n",
    "                #     keys=[\"image\", \"label\"],\n",
    "                #     label_key=\"label\",\n",
    "                #     spatial_size=spatial_size_xyz,\n",
    "                #     pos=1,\n",
    "                #     neg=1,\n",
    "                #     num_samples=num_samples,\n",
    "                #     image_key=\"image\",\n",
    "                #     image_threshold=0,\n",
    "                # ),\n",
    "                RandSpatialCropSamplesd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    roi_size=spatial_size_xyz,\n",
    "                    num_samples=num_samples,\n",
    "                    random_size=False\n",
    "                ),\n",
    "                RandSimulateLowResolutiond(keys=[\"image\"], prob=0.35),\n",
    "                RandGaussianNoised(keys=[\"image\"], std=0.01, prob=0.1),\n",
    "                RandGaussianSmoothd(\n",
    "                    keys=[\"image\"],\n",
    "                    sigma_x=(0.5, 1.15),\n",
    "                    sigma_y=(0.5, 1.15),\n",
    "                    sigma_z=(0.5, 1.15),\n",
    "                    prob=0.2    ,\n",
    "                )\n",
    "                \n",
    "                \n",
    "                # RandShiftIntensityd(\n",
    "                #     keys=[\"image\"],\n",
    "                #     offsets=0.10,\n",
    "                #     prob=0.10,\n",
    "                # ),\n",
    "            ]\n",
    "            ) \n",
    "    \n",
    "        \n",
    "    \n",
    "    val_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"], ensure_channel_first=True),\n",
    "            # ScaleIntensityRanged(keys=[\"image\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
    "            # Orientationd(keys=[\"image\", \"label\"], axcodes=\"LPS\"),\n",
    "            EnsureTyped(keys=[\"image\", \"label\"], device=device, track_meta=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"], ensure_channel_first=True),\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"LPS\"),\n",
    "            Spacingd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                pixdim=(space_x, space_y, space_z),\n",
    "                mode=(\"bilinear\", \"nearest\"),\n",
    "            ),\n",
    "            EnsureTyped(keys=[\"image\", \"label\"], device=device, track_meta=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    split_json = json_name\n",
    "    \n",
    "    datasets = data_dir + split_json\n",
    "    datalist = load_decathlon_datalist(datasets, True, \"training\")\n",
    "    val_files = load_decathlon_datalist(datasets, True, \"validation\")\n",
    "    train_ds = CacheDataset(\n",
    "        data=datalist,\n",
    "        transform=train_transforms,\n",
    "        cache_num=40,\n",
    "        cache_rate=1.0,\n",
    "        num_workers=8,\n",
    "    )\n",
    "    train_loader = ThreadDataLoader(train_ds, num_workers=0, batch_size=1, shuffle=True)\n",
    "    val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_num=0, cache_rate=1.0, num_workers=4)\n",
    "    val_loader = ThreadDataLoader(val_ds, num_workers=0, batch_size=1)\n",
    "\n",
    "\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    OAR_nums_plus_one = 9\n",
    "    patch_size = list(spatial_size_xyz)\n",
    "    spacing = [1.0, 1.0, 1.0]\n",
    "    ks, st = get_kernels_strides(patch_size, spacing)\n",
    "    print(ks, st)\n",
    "    uks = st[1:]\n",
    "    #dynunet hyperparameter\n",
    "   \n",
    "    # ks = [[3, 3, 1], [3, 3, 3], [3, 3, 3], [3, 3, 3]]\n",
    "    # st = [[1, 1, 1], [2, 2, 1], [2, 2, 2], [2, 2, 1]]\n",
    "    uks = st[1:]\n",
    "\n",
    "    # model = UNETR(\n",
    "    # img_size=spatial_size_xyz,\n",
    "    # in_channels=5,\n",
    "    # out_channels=OAR_nums_plus_one,\n",
    "    # ).to(device)\n",
    "    # model = SegResNet(in_channels = 5, out_channels = OAR_nums_plus_one, dropout_prob = 0.3, act=\"LEAKYRELU\").to(device)\n",
    "    model = DynUNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=2,\n",
    "        out_channels=OAR_nums_plus_one,\n",
    "        kernel_size=ks,\n",
    "        strides=st,\n",
    "        upsample_kernel_size=uks,\n",
    "        dropout=0.1,\n",
    "        act_name= \"LEAKYRELU\",\n",
    "        deep_supervision=False\n",
    "    ).to(device)\n",
    "    # model = SwinUNETR(\n",
    "    # img_size=(64, 64, 32),\n",
    "    # in_channels=5,\n",
    "    # out_channels=OAR_nums_plus_one,\n",
    "    # feature_size=48,\n",
    "    # use_checkpoint=False,\n",
    "    # ).to(device)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    #FOR SINGLE CHANNEL PREDICTION\n",
    "    loss_function = DiceCELoss(to_onehot_y=OAR_nums_plus_one, softmax=True)\n",
    "    initial_lr = 1e-2\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=initial_lr, weight_decay=3e-5, momentum=0.99, nesterov=True)\n",
    "    # optimizer = torch.optim.AdamW(model.parameters(), lr=initial_lr, weight_decay=1e-5)\n",
    "    # scheduler = CosineAnnealingNoWarmUpRestarts(optimizer, 5, 2, 1e-2, 0, 0, 0.8)\n",
    "    T_0 = 20\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=T_0, T_mult=2, eta_min=0)\n",
    "    scheduler = PolyLRScheduler(optimizer, initial_lr=initial_lr, max_steps=1000)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "    import gc\n",
    "    import random\n",
    "    def validation(epoch_iterator_val):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_min = -1024\n",
    "            total_max = 3071\n",
    "            bone_min = -1000\n",
    "            bone_max = 2000\n",
    "            soft_min = -160\n",
    "            soft_max = 350\n",
    "            brain_min = -5\n",
    "            brain_max = 65\n",
    "            stroke_min = 15\n",
    "            stroke_max = 45\n",
    "\n",
    "            for batch in epoch_iterator_val:\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                val_inputs, val_labels = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "                \n",
    "                tx =  torch.reshape(val_inputs[:, 0, :, :, :].clone().detach(), (val_inputs.shape[0], 1, val_inputs.shape[2], val_inputs.shape[3], val_inputs.shape[4]))\n",
    "                # x1 =  torch.reshape(val_inputs[:, 0, :, :, :].clone().detach(), (val_inputs.shape[0], 1, val_inputs.shape[2], val_inputs.shape[3], val_inputs.shape[4]))\n",
    "                x2 =  torch.reshape(val_inputs[:, 0, :, :, :].clone().detach(), (val_inputs.shape[0], 1, val_inputs.shape[2], val_inputs.shape[3], val_inputs.shape[4]))\n",
    "                # x3 =  torch.reshape(val_inputs[:, 0, :, :, :].clone().detach(), (val_inputs.shape[0], 1, val_inputs.shape[2], val_inputs.shape[3], val_inputs.shape[4]))\n",
    "                # x4 =  torch.reshape(val_inputs[:, 0, :, :, :].clone().detach(), (val_inputs.shape[0], 1, val_inputs.shape[2], val_inputs.shape[3], val_inputs.shape[4]))\n",
    "                tx[tx<total_min] = total_min\n",
    "                tx[tx>total_max] = total_max\n",
    "                tx = (tx-total_min)/(total_max-total_min)\n",
    "                # x1[x1<bone_min] = bone_min\n",
    "                # x1[x1>bone_max] = bone_max\n",
    "                # x1 = (x1-bone_min)/(bone_max-bone_min)\n",
    "                x2[x2<soft_min] = soft_min\n",
    "                x2[x2>soft_max] = soft_max\n",
    "                x2 = (x2-soft_min)/(soft_max-soft_min)\n",
    "                # x3[x3<brain_min] = brain_min\n",
    "                # x3[x3>brain_max] = brain_max \n",
    "                # x3 = (x3-brain_min)/(brain_max-brain_min)\n",
    "                # x4[x4<stroke_min] = stroke_min\n",
    "                # x4[x4>stroke_max] = stroke_max\n",
    "                # x4 = (x4 - stroke_min)/(stroke_max - stroke_min)\n",
    "                tx *= 2\n",
    "                tx -= 1\n",
    "                x2 *= 2\n",
    "                x2 -= 1\n",
    "\n",
    "                # tx *= 10\n",
    "                # x2 *= 2\n",
    "\n",
    "\n",
    "                val_inputs = torch.cat((tx, x2), 1)\n",
    "\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    val_outputs = sliding_window_inference(val_inputs, spatial_size_xyz, 4, model)\n",
    "                val_labels_list = decollate_batch(val_labels)\n",
    "                val_labels_convert = [post_label(val_label_tensor) for val_label_tensor in val_labels_list]\n",
    "                val_outputs_list = decollate_batch(val_outputs)\n",
    "                val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
    "                dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "                epoch_iterator_val.set_description(\"Validate (%d / %d Steps)\" % (global_step, 10.0))\n",
    "            mean_dice_val = dice_metric.aggregate().item()\n",
    "            dice_metric.reset()\n",
    "        return mean_dice_val\n",
    "\n",
    "    from PIL import Image\n",
    "    def train(global_step, train_loader, dice_val_best, global_step_best, t_0):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        # rand_fliper_x = RandFlip(prob=0.5, spatial_axis=0)\n",
    "        # rand_fliper_y = RandFlip(prob=0.1, spatial_axis=1)\n",
    "        # rand_fliper_z = RandFlip(prob=0.1, spatial_axis=2)\n",
    "        randcontrast = RandAdjustContrast(prob=0.3, gamma=(0.7, 1.5))\n",
    "        randintensity = RandShiftIntensity(prob=0.15, offsets=0.4)\n",
    "        #randlowsim = RandSimulateLowResolution(prob=0.25)\n",
    "        epoch_iterator = tqdm(train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True)\n",
    "        print(optimizer.param_groups[0]['lr'])\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            step += 1\n",
    "            x, y = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "            # img = x[0, 0, ...].clone.detach().cpu().numpy()\n",
    "            \n",
    "            #print(x.shape)\n",
    "            #x = torch.transpose(x, 1, 0)\n",
    "           # print(x.shape)\n",
    "           # x = rand_fliper_x(x)\n",
    "          #  x = rand_fliper_y(x)\n",
    "           # x = rand_fliper_z(x)\n",
    "           # x = torch.transpose(x, 1, 0)\n",
    "          #  print(x.shape)\n",
    "            total_min = -1024\n",
    "            total_max = 3071\n",
    "            # bone_min = random.randrange(-1024, -699, 1)\n",
    "            # bone_max = random.randrange(1850, 2151, 1)\n",
    "            soft_min = random.randrange(-250, -149, 1)\n",
    "            soft_max = random.randrange(290, 391, 1)\n",
    "            # brain_min = random.randrange(-10, 0, 1)\n",
    "            # brain_max = random.randrange(40, 91, 1)\n",
    "            # stroke_min = random.randrange(10, 21, 1)\n",
    "            # stroke_max = random.randrange(40, 51, 1)\n",
    "            \n",
    "            tx =  torch.reshape(x[:, 0, :, : ,:].clone().detach(), (x.shape[0], 1, x.shape[2], x.shape[3], x.shape[4]))\n",
    "            # x1 =  torch.reshape(x[:, 0, :, : ,:].clone().detach(), (x.shape[0], 1, x.shape[2], x.shape[3], x.shape[4]))\n",
    "            x2 =  torch.reshape(x[:, 0, :, : ,:].clone().detach(), (x.shape[0], 1, x.shape[2], x.shape[3], x.shape[4]))\n",
    "            # x3 =  torch.reshape(x[:, 0, :, : ,:].clone().detach(), (x.shape[0], 1, x.shape[2], x.shape[3], x.shape[4]))\n",
    "            # x4 =  torch.reshape(x[:, 0, :, : ,:].clone().detach(), (x.shape[0], 1, x.shape[2], x.shape[3], x.shape[4]))\n",
    "            \n",
    "            tx[tx<total_min] = total_min\n",
    "            tx[tx>total_max] = total_max\n",
    "            tx = (tx-total_min)/(total_max-total_min)\n",
    "            \n",
    "            # x1[x1<bone_min] = bone_min\n",
    "            # x1[x1>bone_max] = bone_max\n",
    "            # x1 = (x1-bone_min)/(bone_max-bone_min)\n",
    "            x2[x2<soft_min] = soft_min\n",
    "            x2[x2>soft_max] = soft_max\n",
    "            x2 = (x2-soft_min)/(soft_max-soft_min)\n",
    "            tx = randintensity(tx)\n",
    "            tx = randcontrast(tx)\n",
    "            \n",
    "            x2 = randintensity(x2)\n",
    "            x2 = randcontrast(x2)\n",
    "            \n",
    "            \n",
    "            # x3[x3<brain_min] = brain_min\n",
    "            # x3[x3>brain_max] = brain_max \n",
    "            # x3 = (x3-brain_min)/(brain_max-brain_min)\n",
    "            # x4[x4 < stroke_min] = stroke_min\n",
    "            # x4[x4 > stroke_max] = stroke_max\n",
    "            # x4 = (x4 - stroke_min)/(stroke_max - stroke_min)\n",
    "            # tx *= 10\n",
    "            # x2 *= 2\n",
    "            tx *= 2\n",
    "            tx -= 1\n",
    "            x2 *= 2\n",
    "            x2 -= 1\n",
    "            x = torch.cat((tx, x2), 1)\n",
    "            #x = randlowsim(x)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logit_map = model(x)\n",
    "                loss = loss_function(logit_map, y)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            epoch_loss += loss.item()\n",
    "            scaler.unscale_(optimizer)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            epoch_iterator.set_description(f\"Training ({global_step} / {max_iterations} Steps) (loss={loss:2.5f})\")\n",
    "            if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations:\n",
    "                epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "                dice_val = validation(epoch_iterator_val)\n",
    "                epoch_loss /= step\n",
    "                epoch_loss_values.append(epoch_loss)\n",
    "                metric_values.append(dice_val)\n",
    "                if dice_val > dice_val_best:\n",
    "                    dice_val_best = dice_val\n",
    "                    global_step_best = global_step\n",
    "                    torch.save({\n",
    "                        'global_step': global_step,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    }, os.path.join(model_savepath, \"zone1_model_epoch_SGD_%d_%.3f.pth\" %(global_step, float(dice_val))))\n",
    "                    print(\n",
    "                        \"Model Was Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(dice_val_best, dice_val)\n",
    "                    )\n",
    "                else:\n",
    "                    print(\n",
    "                        \"Model Was Not Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                            dice_val_best, dice_val\n",
    "                        )\n",
    "                    )\n",
    "                print(optimizer.param_groups[0]['lr'])\n",
    "                # scheduler.step()\n",
    "            # if global_step % 250 == 0 and global_step != 0:\n",
    "                scheduler.step()\n",
    "                print(\"scheduler is steped!\")\n",
    "            global_step += 1\n",
    "        # print((global_step+1) // (len(train_ds)) % t_0)\n",
    "        # if (global_step+1) // (len(train_ds)) % t_0 == 0:\n",
    "        #     print(\"donedone\")\n",
    "        #     scheduler.base_lrs[0] = scheduler.base_lrs[0] * (0.7)\n",
    "        #     t_0 *= 2\n",
    "        \n",
    "        return global_step, dice_val_best, global_step_best, t_0\n",
    "     \n",
    "    max_iterations = 250000\n",
    "    eval_num = 250\n",
    "    post_label = AsDiscrete(to_onehot=OAR_nums_plus_one)\n",
    "    post_pred = AsDiscrete(argmax=True, to_onehot=OAR_nums_plus_one)\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "    global_step = 0\n",
    "    dice_val_best = 0.0\n",
    "    global_step_best = 0\n",
    "    epoch_loss_values = []\n",
    "    metric_values = []\n",
    "    t_0 = T_0\n",
    "    while global_step < max_iterations:\n",
    "        global_step, dice_val_best, global_step_best, t_0 = train(global_step, train_loader, dice_val_best, global_step_best, t_0=t_0)\n",
    "        epoch_loss_npy = np.array(epoch_loss_values)\n",
    "        np.save(os.path.join(loss_savepath, \"%d_loss.npy\" %(int(global_step))), epoch_loss_npy)\n",
    "    # total_case_num = 24\n",
    "    # model.load_state_dict(torch.load(os.path.join(root_dir, name_oar.lower() + \"_model_fold0_0.pth\")))\n",
    "    # model.eval()\n",
    "    # original_nib_path = root_dir + r\"/imcroppedval\"\n",
    "    # original_nib_path_list = os.listdir(original_nib_path)\n",
    "    return None\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     for case_num in range(total_case_num):\n",
    "    #         start = time.time()\n",
    "    #         template_nib = nib.load(os.path.join(original_nib_path, original_nib_path_list[case_num]))\n",
    "\n",
    "    #         img_name = os.path.split(val_ds[case_num][\"image\"].meta[\"filename_or_obj\"])[1]\n",
    "    #         img = val_ds[case_num][\"image\"]\n",
    "    #         label = val_ds[case_num][\"label\"]\n",
    "    #         val_inputs = torch.unsqueeze(img, 0).cuda()\n",
    "    #         val_labels = torch.unsqueeze(label, 0).cuda()\n",
    "    #         bone_min = -1000\n",
    "    #         bone_max = 2000\n",
    "    #         soft_min = -160\n",
    "    #         soft_max = 350\n",
    "    #         brain_min = -5\n",
    "    #         brain_max = 65\n",
    "    #         stroke_min = 15\n",
    "    #         stroke_max = 45\n",
    "\n",
    "    #         # box_start, box_end = FG_cropper.compute_bounding_box(val_inputs)\n",
    "    #         tx =  torch.reshape(val_inputs[:, 0, :, :, :].clone().detach(), (val_inputs.shape[0], 1, val_inputs.shape[2], val_inputs.shape[3], val_inputs.shape[4]))\n",
    "    #         x1 =  torch.reshape(val_inputs[:, 0, :, :, :].clone().detach(), (val_inputs.shape[0], 1, val_inputs.shape[2], val_inputs.shape[3], val_inputs.shape[4]))\n",
    "    #         x2 =  torch.reshape(val_inputs[:, 0, :, :, :].clone().detach(), (val_inputs.shape[0], 1, val_inputs.shape[2], val_inputs.shape[3], val_inputs.shape[4]))\n",
    "    #         x3 =  torch.reshape(val_inputs[:, 0, :, :, :].clone().detach(), (val_inputs.shape[0], 1, val_inputs.shape[2], val_inputs.shape[3], val_inputs.shape[4]))\n",
    "    #         x4 =  torch.reshape(val_inputs[:, 0, :, :, :].clone().detach(), (val_inputs.shape[0], 1, val_inputs.shape[2], val_inputs.shape[3], val_inputs.shape[4]))\n",
    "    #         tx2 = torch.reshape(val_inputs[:, 1, :, :, :].clone().detach(), (val_inputs.shape[0], 1, val_inputs.shape[2], val_inputs.shape[3], val_inputs.shape[4]))\n",
    "    #         x1[x1<bone_min] = bone_min\n",
    "    #         x1[x1>bone_max] = bone_max\n",
    "    #         x1 = (x1-bone_min)/(bone_max-bone_min)\n",
    "    #         x2[x2<soft_min] = soft_min\n",
    "    #         x2[x2>soft_max] = soft_max\n",
    "    #         x2 = (x2-soft_min)/(soft_max-soft_min)\n",
    "    #         x3[x3<brain_min] = brain_min\n",
    "    #         x3[x3>brain_max] = brain_max \n",
    "    #         x3 = (x3-brain_min)/(brain_max-brain_min)\n",
    "    #         x4[x4<stroke_min] = stroke_min\n",
    "    #         x4[x4>stroke_max] = stroke_max\n",
    "    #         x4 = (x4 - stroke_min)/(stroke_max - stroke_min)\n",
    "    #         val_inputs = torch.cat((tx, x1, x2, x3, x4, tx2), 1)\n",
    "\n",
    "    #         val_outputs = sliding_window_inference(val_inputs, spatial_size_xyz, 4, model, overlap=0.5)\n",
    "    #         last_outputs = torch.argmax(val_outputs, dim=1).detach().cpu()[0].numpy()\n",
    "    #         img_npy = img.cpu()[0].numpy()\n",
    "    #         label_npy = label.cpu()[0].numpy()\n",
    "    #         print(\"time taken : %f\" %(time.time()- start))\n",
    "    #         # nib.save(\n",
    "    #                 # nib.Nifti1Image(img_npy.astype(np.uint8), np.ones((4, 4))), os.path.join(r\"D:\\!HaN_Challenge\\HaN-Seg_NRRD\\!output_dir\\label_1to10_fold0\", \"val_ct_%02d\" %(case_num+1))\n",
    "    #             # )\n",
    "\n",
    "    #         nib.save(\n",
    "    #                 nib.Nifti1Image(label_npy.astype(np.uint8), template_nib.affine, template_nib.header), os.path.join(root_dir + \"/result\", \"val_label_%02d\" %(case_num+1))\n",
    "    #             )\n",
    "    #         nib.save(\n",
    "    #                 nib.Nifti1Image(last_outputs.astype(np.uint8), template_nib.affine, template_nib.header), os.path.join(root_dir + \"/result\", \"infered_label_%02d\" %(case_num+1))\n",
    "    #             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "json_name_list = [\n",
    "                # \"dataset_f0_fold00.json\", \n",
    "                #\"dataset_f0_fold01.json\", \n",
    "                \"dataset_f0_fold02.json\", \n",
    "                \"dataset_f0_fold03.json\", \n",
    "                \"dataset_f0_fold04.json\"]\n",
    "for json in json_name_list:\n",
    "    oar_run_train(json)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fold 0 \n",
    "arytenoid 0.64386\n",
    "a_carotid_l 0.83728 (아마이것보단 높을것)\n",
    "a_carotid_r 0.88483\n",
    "bone_mandible 0.964496\n",
    "oralcavity 0.924\n",
    "cochlea_l 0.85533\n",
    "optnr_1 0.77\n",
    "\n",
    "fold 1 \n",
    "arytenoid 0.45... 가우시안 노이즈 + 가우시안 블러링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swinjupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
